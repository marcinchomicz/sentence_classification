{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas              \t1.5.0\n",
      "tensorflow          \t2.9.2\n",
      "tensorflow_addons   \t0.18.0\n",
      "mlflow              \t1.29.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import mlflow\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "for m in [pd, tf, tfa, mlflow]:\n",
    "    print(f\"{m.__name__:20s}\\t{m.__version__}\")\n",
    "\n",
    "# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "tf.config.experimental.enable_tensor_float_32_execution(enabled=True)\n",
    "\n",
    "OUTPUTPATH = \"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/sandbox/\"\n",
    "DATAPATH = \"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/dataset/enron_files_annotated/\"\n",
    "FILESTORE = \"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/tmp/\"\n",
    "MLFLOW_DIR = \"file:///mnt/workdata/_WORK_/mail_zonning/mail_zoning/mlruns/\"\n",
    "TENSORBOARD_DIR = '/mnt/workdata/_WORK_/mail_zonning/mail_zoning/optim/sequenced_bilstm/tblogs/'\n",
    "ENAME = 'SEQUENCED_CBiGRU_iter_0'\n",
    "\n",
    "BOM_SIGNAL = 'the start of the email signal, no lines before'\n",
    "EOM_SIGNAL = 'the end of the email signal, no lines after'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sys.path.append(\"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/sandbox/\")\n",
    "from sentence_classifier import SentenceClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def prepare_dataset(datapath: str):\n",
    "    def extract_text(text, flags: dict):\n",
    "        text = text.split('\\n')\n",
    "        idx = 0\n",
    "        while text[idx][:2] not in flags:\n",
    "            idx += 1\n",
    "        labels = [flags[t[:2]] for t in text[idx:] if len(t) > 1]\n",
    "        text = [t[2:] for t in text[idx:]]\n",
    "        return text, labels\n",
    "\n",
    "    # load and extract flag data\n",
    "    FLAGS = {'B>': 0, 'H>': 1, 'S>': 2}\n",
    "    files = {}\n",
    "    for filename in os.listdir(datapath):\n",
    "        with open(os.path.join(datapath, filename), 'rt') as f:\n",
    "            files[filename] = f.read()\n",
    "    _ = []\n",
    "    for filename in files.keys():\n",
    "        text_ = files[filename]\n",
    "        textlines, labels = extract_text(text_, FLAGS)\n",
    "        for idx, line_label in enumerate(zip(textlines, labels)):\n",
    "            _.append({'doc': filename, 'idx': idx, 'sentence': line_label[0], 'label': line_label[1]})\n",
    "    df = pd.DataFrame.from_dict(_)\n",
    "    return df\n",
    "\n",
    "def split_dataset(data: pd.DataFrame, random_state: int):\n",
    "    \"\"\"\"\n",
    "    Dataset split is based on complete emails, not on email lines\n",
    "    \"\"\"\n",
    "    splitter = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    docs = data['doc'].unique()\n",
    "    splits = splitter.split(docs)\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for train_idx, val_idx in splits:\n",
    "        train_data_ = data.loc[data['doc'].isin(docs[train_idx])]\n",
    "        train_data.append(train_data_[['doc', 'idx', 'sentence', 'label']])\n",
    "        val_data_ = data.loc[data['doc'].isin(docs[val_idx])]\n",
    "        val_data.append(val_data_[['doc', 'idx', 'sentence', 'label']])\n",
    "    return train_data, val_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 3,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 23:11:21.268492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.275478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.275709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.276351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 23:11:21.279060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.279264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.279441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.608464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.608635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.608767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-03 23:11:21.608848: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-12-03 23:11:21.608870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 23:11:26.664605: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2022-12-03 23:11:27.108471: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-03 23:11:27.750080: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 12ms/step - loss: 0.2656 - accuracy: 0.9034 - val_loss: 0.4067 - val_accuracy: 0.8574 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0580 - accuracy: 0.9834 - val_loss: 0.1608 - val_accuracy: 0.9626 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: 0.0851 - val_accuracy: 0.9799 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.0635 - val_accuracy: 0.9846 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0327 - accuracy: 0.9907 - val_loss: 0.0836 - val_accuracy: 0.9745 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0560 - val_accuracy: 0.9835 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.0626 - val_accuracy: 0.9806 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.0791 - val_accuracy: 0.9777 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0797 - val_accuracy: 0.9802 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0805 - val_accuracy: 0.9788 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0843 - val_accuracy: 0.9788 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0924 - val_accuracy: 0.9741 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9929 - val_loss: 0.0891 - val_accuracy: 0.9774 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0878 - val_accuracy: 0.9781 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0816 - val_accuracy: 0.9795 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0822 - val_accuracy: 0.9795 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9835\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 5s 12ms/step - loss: 0.2549 - accuracy: 0.9090 - val_loss: 0.3922 - val_accuracy: 0.8367 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.1461 - val_accuracy: 0.9761 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0650 - val_accuracy: 0.9821 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 0.0536 - val_accuracy: 0.9832 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.0818 - val_accuracy: 0.9772 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 0.0843 - val_accuracy: 0.9757 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 1s 8ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.1252 - val_accuracy: 0.9634 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.0886 - val_accuracy: 0.9780 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0986 - val_accuracy: 0.9765 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9929 - val_loss: 0.1013 - val_accuracy: 0.9757 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0935 - val_accuracy: 0.9757 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.0942 - val_accuracy: 0.9757 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0930 - val_accuracy: 0.9765 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.0987 - val_accuracy: 0.9757 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9832\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 5s 12ms/step - loss: 0.2546 - accuracy: 0.9093 - val_loss: 0.3748 - val_accuracy: 0.8788 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0555 - accuracy: 0.9839 - val_loss: 0.1695 - val_accuracy: 0.9549 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.1365 - val_accuracy: 0.9672 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0331 - accuracy: 0.9910 - val_loss: 0.2566 - val_accuracy: 0.9343 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.2351 - val_accuracy: 0.9413 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.3203 - val_accuracy: 0.9340 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.2606 - val_accuracy: 0.9444 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.2508 - val_accuracy: 0.9465 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.3021 - val_accuracy: 0.9410 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.3100 - val_accuracy: 0.9423 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.3428 - val_accuracy: 0.9416 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.3371 - val_accuracy: 0.9403 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.3430 - val_accuracy: 0.9403 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9672\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 5s 12ms/step - loss: 0.2502 - accuracy: 0.9118 - val_loss: 0.5150 - val_accuracy: 0.7258 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.2096 - val_accuracy: 0.9518 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9904 - val_loss: 0.1544 - val_accuracy: 0.9508 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0311 - accuracy: 0.9911 - val_loss: 0.0705 - val_accuracy: 0.9803 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 0.0691 - val_accuracy: 0.9813 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0777 - val_accuracy: 0.9819 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0821 - val_accuracy: 0.9803 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.0723 - val_accuracy: 0.9816 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0920 - val_accuracy: 0.9789 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.0902 - val_accuracy: 0.9816 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0928 - val_accuracy: 0.9809 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.0871 - val_accuracy: 0.9813 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0856 - val_accuracy: 0.9806 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.0849 - val_accuracy: 0.9813 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0867 - val_accuracy: 0.9813 - lr: 5.7401e-05\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9813\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 12ms/step - loss: 0.2786 - accuracy: 0.8985 - val_loss: 0.3628 - val_accuracy: 0.8642 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0579 - accuracy: 0.9829 - val_loss: 0.1207 - val_accuracy: 0.9709 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.0881 - val_accuracy: 0.9795 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.1514 - val_accuracy: 0.9766 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.1120 - val_accuracy: 0.9680 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.1104 - val_accuracy: 0.9742 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.1097 - val_accuracy: 0.9733 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.1111 - val_accuracy: 0.9758 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.1220 - val_accuracy: 0.9737 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.1144 - val_accuracy: 0.9746 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.1179 - val_accuracy: 0.9737 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.1242 - val_accuracy: 0.9766 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.1250 - val_accuracy: 0.9746 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9795\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=SentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "master_results={3:results}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 5,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 6s 13ms/step - loss: 0.2232 - accuracy: 0.9159 - val_loss: 0.4076 - val_accuracy: 0.8376 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0953 - val_accuracy: 0.9795 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0387 - val_accuracy: 0.9896 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0207 - val_accuracy: 0.9932 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0342 - val_accuracy: 0.9881 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.0431 - val_accuracy: 0.9889 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0227 - val_accuracy: 0.9932 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0228 - val_accuracy: 0.9935 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0230 - val_accuracy: 0.9928 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0283 - val_accuracy: 0.9907 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0241 - val_accuracy: 0.9921 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0243 - val_accuracy: 0.9921 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0241 - val_accuracy: 0.9921 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0238 - val_accuracy: 0.9921 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 6s 14ms/step - loss: 0.2058 - accuracy: 0.9238 - val_loss: 0.3632 - val_accuracy: 0.8221 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0745 - val_accuracy: 0.9813 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.0538 - val_accuracy: 0.9821 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0599 - val_accuracy: 0.9821 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.1199 - val_accuracy: 0.9716 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0962 - val_accuracy: 0.9806 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0682 - val_accuracy: 0.9839 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0662 - val_accuracy: 0.9843 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1278 - val_accuracy: 0.9753 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0866 - val_accuracy: 0.9821 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0852 - val_accuracy: 0.9821 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0965 - val_accuracy: 0.9813 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1017 - val_accuracy: 0.9813 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9821\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 5s 12ms/step - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.3593 - val_accuracy: 0.9008 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0382 - accuracy: 0.9863 - val_loss: 0.1286 - val_accuracy: 0.9745 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.1358 - val_accuracy: 0.9560 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.1454 - val_accuracy: 0.9762 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1589 - val_accuracy: 0.9738 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.1994 - val_accuracy: 0.9542 - lr: 2.8946e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1741 - val_accuracy: 0.9689 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.2264 - val_accuracy: 0.9535 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.2088 - val_accuracy: 0.9633 - lr: 1.2890e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.1933 - val_accuracy: 0.9661 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.2041 - val_accuracy: 0.9630 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1911 - val_accuracy: 0.9675 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9745\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 5s 12ms/step - loss: 0.2099 - accuracy: 0.9241 - val_loss: 0.5166 - val_accuracy: 0.7077 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.1452 - val_accuracy: 0.9666 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.0890 - val_accuracy: 0.9676 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0493 - val_accuracy: 0.9843 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0376 - val_accuracy: 0.9873 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0633 - val_accuracy: 0.9806 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1029 - val_accuracy: 0.9789 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0490 - val_accuracy: 0.9883 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0282 - val_accuracy: 0.9906 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0420 - val_accuracy: 0.9906 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0297 - val_accuracy: 0.9920 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0316 - val_accuracy: 0.9913 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0314 - val_accuracy: 0.9913 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0319 - val_accuracy: 0.9913 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0297 - val_accuracy: 0.9920 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0310 - val_accuracy: 0.9913 - lr: 5.7401e-05\n",
      "Epoch 17/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0318 - val_accuracy: 0.9913 - lr: 5.7401e-05\n",
      "Epoch 18/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0320 - val_accuracy: 0.9913 - lr: 5.7401e-05\n",
      "Epoch 19/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0328 - val_accuracy: 0.9913 - lr: 2.5561e-05\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9906\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 11ms/step - loss: 0.2223 - accuracy: 0.9150 - val_loss: 0.3554 - val_accuracy: 0.8064 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0954 - val_accuracy: 0.9725 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0629 - val_accuracy: 0.9881 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0694 - val_accuracy: 0.9910 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0753 - val_accuracy: 0.9889 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0908 - val_accuracy: 0.9828 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0925 - val_accuracy: 0.9832 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0873 - val_accuracy: 0.9856 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0904 - val_accuracy: 0.9889 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0906 - val_accuracy: 0.9856 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0905 - val_accuracy: 0.9856 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0889 - val_accuracy: 0.9865 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0895 - val_accuracy: 0.9848 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9881\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=SentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "master_results[5]=results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 7,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 6s 13ms/step - loss: 0.2147 - accuracy: 0.9155 - val_loss: 0.3969 - val_accuracy: 0.8240 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0340 - accuracy: 0.9888 - val_loss: 0.1070 - val_accuracy: 0.9608 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0209 - val_accuracy: 0.9921 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0269 - val_accuracy: 0.9892 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0198 - val_accuracy: 0.9917 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0134 - val_accuracy: 0.9957 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0130 - val_accuracy: 0.9960 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0188 - val_accuracy: 0.9928 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0281 - val_accuracy: 0.9896 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0132 - val_accuracy: 0.9957 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0238 - val_accuracy: 0.9925 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0151 - val_accuracy: 0.9939 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0244 - val_accuracy: 0.9910 - lr: 2.8946e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0164 - val_accuracy: 0.9939 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9917 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0135 - val_accuracy: 0.9953 - lr: 1.2890e-04\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0154 - val_accuracy: 0.9939 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9960\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 6s 13ms/step - loss: 0.2135 - accuracy: 0.9208 - val_loss: 0.3507 - val_accuracy: 0.8371 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0328 - accuracy: 0.9881 - val_loss: 0.0826 - val_accuracy: 0.9798 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0407 - val_accuracy: 0.9907 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0343 - val_accuracy: 0.9880 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0252 - val_accuracy: 0.9944 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0464 - val_accuracy: 0.9854 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0238 - val_accuracy: 0.9963 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0251 - val_accuracy: 0.9951 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0867 - val_accuracy: 0.9772 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0324 - val_accuracy: 0.9929 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0364 - val_accuracy: 0.9910 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0534 - val_accuracy: 0.9869 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0545 - val_accuracy: 0.9869 - lr: 2.8946e-04\n",
      "Epoch 14/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0357 - val_accuracy: 0.9929 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0438 - val_accuracy: 0.9899 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0322 - val_accuracy: 0.9922 - lr: 1.2890e-04\n",
      "Epoch 17/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0404 - val_accuracy: 0.9907 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9963\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 5s 12ms/step - loss: 0.2162 - accuracy: 0.9167 - val_loss: 0.3072 - val_accuracy: 0.8906 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 0.1413 - val_accuracy: 0.9472 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.1440 - val_accuracy: 0.9682 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.2234 - val_accuracy: 0.9486 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3550 - val_accuracy: 0.9326 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.3443 - val_accuracy: 0.9364 - lr: 2.8946e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2300 - val_accuracy: 0.9595 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.3267 - val_accuracy: 0.9483 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3104 - val_accuracy: 0.9469 - lr: 1.2890e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3375 - val_accuracy: 0.9469 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.3040 - val_accuracy: 0.9497 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2959 - val_accuracy: 0.9490 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9472\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 5s 13ms/step - loss: 0.2194 - accuracy: 0.9240 - val_loss: 0.5372 - val_accuracy: 0.7883 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0435 - accuracy: 0.9837 - val_loss: 0.1749 - val_accuracy: 0.9365 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0864 - val_accuracy: 0.9753 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.0372 - val_accuracy: 0.9876 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0481 - val_accuracy: 0.9873 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0388 - val_accuracy: 0.9893 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0282 - val_accuracy: 0.9936 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0400 - val_accuracy: 0.9903 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0499 - val_accuracy: 0.9876 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0550 - val_accuracy: 0.9836 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0241 - val_accuracy: 0.9923 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0260 - val_accuracy: 0.9916 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0249 - val_accuracy: 0.9910 - lr: 2.8946e-04\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0285 - val_accuracy: 0.9903 - lr: 2.8946e-04\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0247 - val_accuracy: 0.9910 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0285 - val_accuracy: 0.9903 - lr: 1.2890e-04\n",
      "Epoch 17/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0246 - val_accuracy: 0.9903 - lr: 1.2890e-04\n",
      "Epoch 18/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0305 - val_accuracy: 0.9896 - lr: 5.7401e-05\n",
      "Epoch 19/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0309 - val_accuracy: 0.9890 - lr: 5.7401e-05\n",
      "Epoch 20/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0285 - val_accuracy: 0.9903 - lr: 5.7401e-05\n",
      "Epoch 21/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0301 - val_accuracy: 0.9903 - lr: 2.5561e-05\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 12ms/step - loss: 0.2112 - accuracy: 0.9220 - val_loss: 0.3390 - val_accuracy: 0.9036 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.1127 - val_accuracy: 0.9631 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.1011 - val_accuracy: 0.9692 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.2547 - val_accuracy: 0.9610 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.2714 - val_accuracy: 0.9586 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.3060 - val_accuracy: 0.9602 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.3348 - val_accuracy: 0.9619 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.3365 - val_accuracy: 0.9602 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.3458 - val_accuracy: 0.9610 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.3429 - val_accuracy: 0.9602 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3469 - val_accuracy: 0.9602 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.3467 - val_accuracy: 0.9602 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.3458 - val_accuracy: 0.9602 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=SentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "master_results[7]=results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "_={(k,s): {'val_loss':master_results[k][s][0], 'val_accuracy': master_results[k][s][1]}\n",
    " for k in master_results.keys() for s in master_results[k].keys()}\n",
    "_ = pd.DataFrame.from_dict(_).T.reset_index()\n",
    "_.columns=['window size','split num', 'val loss', 'val accuracy']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "   window size  split num  val loss  val accuracy\n0            3          0  0.055964      0.983477\n1            3          1  0.053647      0.983184\n2            3          2  0.136493      0.967156\n3            3          3  0.069119      0.981271\n4            3          4  0.088093      0.979491",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window size</th>\n      <th>split num</th>\n      <th>val loss</th>\n      <th>val accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0.055964</td>\n      <td>0.983477</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>0.053647</td>\n      <td>0.983184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>0.136493</td>\n      <td>0.967156</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>0.069119</td>\n      <td>0.981271</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>4</td>\n      <td>0.088093</td>\n      <td>0.979491</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9, 1.0)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x600 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax=plt.subplots(1,2,figsize=(14,6))\n",
    "sns.barplot(data=_, x= 'split num', y='val loss', hue='window size',palette='rainbow', ax=ax[0])\n",
    "sns.barplot(data=_, x= 'split num', y='val accuracy', hue='window size',palette='rainbow', ax=ax[1])\n",
    "ax[1].set_ylim(0.9, 1.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 2,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'windo_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [6], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_subsets)):\n\u001B[1;32m      3\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39mclear_session()\n\u001B[0;32m----> 4\u001B[0m     clf\u001B[38;5;241m=\u001B[39mSentenceClassifier(\n\u001B[1;32m      5\u001B[0m         model_params\u001B[38;5;241m=\u001B[39mmodel_params,\n\u001B[1;32m      6\u001B[0m         bod_line \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis is the first line of document. No lines come before.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      7\u001B[0m         eod_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis is the last line of document. No lines come after.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      8\u001B[0m         corpus\u001B[38;5;241m=\u001B[39mtexts)\n\u001B[1;32m      9\u001B[0m     clf\u001B[38;5;241m.\u001B[39mprepare_train_records(data\u001B[38;5;241m=\u001B[39mtrain_subsets[idx])\n\u001B[1;32m     10\u001B[0m     clf\u001B[38;5;241m.\u001B[39mprepare_validation_records(data\u001B[38;5;241m=\u001B[39mval_subsets[idx])\n",
      "File \u001B[0;32m/mnt/workdata/_WORK_/mail_zonning/mail_zoning/sandbox/sentence_classifier.py:25\u001B[0m, in \u001B[0;36mSentenceClassifier.__init__\u001B[0;34m(self, model_params, bod_line, eod_line, corpus, **kwargs)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     20\u001B[0m              model_params: \u001B[38;5;28mdict\u001B[39m,\n\u001B[1;32m     21\u001B[0m              bod_line:\u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     22\u001B[0m              eod_line:\u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     23\u001B[0m              corpus,\n\u001B[1;32m     24\u001B[0m              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 25\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mmodel_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwindo_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m:\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ErrorWindowSizeToSmall\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_params \u001B[38;5;241m=\u001B[39m model_params\n",
      "\u001B[0;31mKeyError\u001B[0m: 'windo_size'"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=SentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py38_tf29",
   "language": "python",
   "display_name": "py38_tf29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
