{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchomicz/envs/env_py38_tf29/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas              \t1.5.0\n",
      "tensorflow          \t2.9.2\n",
      "tensorflow_addons   \t0.18.0\n",
      "mlflow              \t1.29.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/classes\")\n",
    "\n",
    "import datetime as dt\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import mlflow\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_classifier import MovingWindowSentenceClassifier\n",
    "\n",
    "for m in [pd, tf, tfa, mlflow]:\n",
    "    print(f\"{m.__name__:20s}\\t{m.__version__}\")\n",
    "\n",
    "tf.config.experimental.enable_tensor_float_32_execution(enabled=True)\n",
    "\n",
    "DATAPATH = \"/mnt/workdata/_WORK_/mail_zonning/mail_zoning/dataset/enron_files_annotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "start=dt.datetime.now()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supporting methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def prepare_dataset(datapath: str):\n",
    "    def extract_text(text, flags: dict):\n",
    "        text = text.split('\\n')\n",
    "        idx = 0\n",
    "        while text[idx][:2] not in flags:\n",
    "            idx += 1\n",
    "        labels = [flags[t[:2]] for t in text[idx:] if len(t) > 1]\n",
    "        text = [t[2:] for t in text[idx:]]\n",
    "        return text, labels\n",
    "\n",
    "    # load and extract flag data\n",
    "    FLAGS = {'B>': 0, 'H>': 1, 'S>': 2}\n",
    "    files = {}\n",
    "    for filename in os.listdir(datapath):\n",
    "        with open(os.path.join(datapath, filename), 'rt') as f:\n",
    "            files[filename] = f.read()\n",
    "    _ = []\n",
    "    for filename in files.keys():\n",
    "        text_ = files[filename]\n",
    "        textlines, labels = extract_text(text_, FLAGS)\n",
    "        for idx, line_label in enumerate(zip(textlines, labels)):\n",
    "            _.append({'doc': filename, 'idx': idx, 'sentence': line_label[0], 'label': line_label[1]})\n",
    "    df = pd.DataFrame.from_dict(_)\n",
    "    return df\n",
    "\n",
    "def split_dataset(data: pd.DataFrame, random_state: int):\n",
    "    \"\"\"\"\n",
    "    Dataset split is based on complete emails, not on email lines\n",
    "    \"\"\"\n",
    "    splitter = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    docs = data['doc'].unique()\n",
    "    splits = splitter.split(docs)\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for train_idx, val_idx in splits:\n",
    "        train_data_ = data.loc[data['doc'].isin(docs[train_idx])]\n",
    "        train_data.append(train_data_[['doc', 'idx', 'sentence', 'label']])\n",
    "        val_data_ = data.loc[data['doc'].isin(docs[val_idx])]\n",
    "        val_data.append(val_data_[['doc', 'idx', 'sentence', 'label']])\n",
    "    return train_data, val_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0, train records: 10966, validation: 2784\n",
      "Liczba wspólnych dla train i val: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 19:08:26.455612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.460348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.460520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.461186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-27 19:08:26.463500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.463646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.463774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.792299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.792477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.792613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-27 19:08:26.792694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-12-27 19:08:26.792716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22292 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 19:08:31.795438: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2022-12-27 19:08:32.227725: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-27 19:08:32.836905: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 12ms/step - loss: 0.2601 - accuracy: 0.9094 - val_loss: 0.4639 - val_accuracy: 0.8998 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0610 - accuracy: 0.9818 - val_loss: 0.1357 - val_accuracy: 0.9551 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0597 - val_accuracy: 0.9838 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.0706 - val_accuracy: 0.9784 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.0617 - val_accuracy: 0.9835 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9916 - val_loss: 0.0717 - val_accuracy: 0.9831 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0601 - val_accuracy: 0.9824 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.0664 - val_accuracy: 0.9820 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0679 - val_accuracy: 0.9795 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0641 - val_accuracy: 0.9799 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.0646 - val_accuracy: 0.9817 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0680 - val_accuracy: 0.9817 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0681 - val_accuracy: 0.9831 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9838\n",
      "Subset: 1, train records: 11074, validation: 2676\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 5s 11ms/step - loss: 0.2681 - accuracy: 0.9019 - val_loss: 0.3819 - val_accuracy: 0.8834 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0593 - accuracy: 0.9814 - val_loss: 0.1206 - val_accuracy: 0.9664 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0369 - accuracy: 0.9899 - val_loss: 0.0698 - val_accuracy: 0.9809 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.0949 - val_accuracy: 0.9753 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.1071 - val_accuracy: 0.9750 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0715 - val_accuracy: 0.9798 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 0.0882 - val_accuracy: 0.9787 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.0933 - val_accuracy: 0.9780 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 1s 8ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.1085 - val_accuracy: 0.9761 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.1072 - val_accuracy: 0.9757 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.0956 - val_accuracy: 0.9772 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 1s 7ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.1063 - val_accuracy: 0.9742 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.1085 - val_accuracy: 0.9765 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9809\n",
      "Subset: 2, train records: 10888, validation: 2862\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 5s 12ms/step - loss: 0.2583 - accuracy: 0.9080 - val_loss: 0.3576 - val_accuracy: 0.8899 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0598 - accuracy: 0.9838 - val_loss: 0.1530 - val_accuracy: 0.9528 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9900 - val_loss: 0.1958 - val_accuracy: 0.9354 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0331 - accuracy: 0.9905 - val_loss: 0.1649 - val_accuracy: 0.9528 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9907 - val_loss: 0.1737 - val_accuracy: 0.9668 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.2007 - val_accuracy: 0.9525 - lr: 2.8946e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.1943 - val_accuracy: 0.9574 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.2819 - val_accuracy: 0.9375 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.2514 - val_accuracy: 0.9458 - lr: 1.2890e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.2545 - val_accuracy: 0.9451 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.2959 - val_accuracy: 0.9399 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.2796 - val_accuracy: 0.9437 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9528\n",
      "Subset: 3, train records: 10760, validation: 2990\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 5s 12ms/step - loss: 0.2838 - accuracy: 0.9031 - val_loss: 0.6005 - val_accuracy: 0.8271 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9822 - val_loss: 0.1938 - val_accuracy: 0.9455 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0392 - accuracy: 0.9897 - val_loss: 0.0881 - val_accuracy: 0.9706 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0918 - val_accuracy: 0.9716 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0913 - val_accuracy: 0.9742 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 0.1330 - val_accuracy: 0.9666 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.1155 - val_accuracy: 0.9696 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.9937 - val_loss: 0.1117 - val_accuracy: 0.9686 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9935 - val_loss: 0.0901 - val_accuracy: 0.9746 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.1128 - val_accuracy: 0.9712 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.1189 - val_accuracy: 0.9699 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1124 - val_accuracy: 0.9706 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.1216 - val_accuracy: 0.9699 - lr: 5.7401e-05\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9706\n",
      "Subset: 4, train records: 11312, validation: 2438\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 11ms/step - loss: 0.2709 - accuracy: 0.9003 - val_loss: 0.3645 - val_accuracy: 0.8802 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0602 - accuracy: 0.9821 - val_loss: 0.1613 - val_accuracy: 0.9422 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0410 - accuracy: 0.9886 - val_loss: 0.1000 - val_accuracy: 0.9725 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.1091 - val_accuracy: 0.9754 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.1225 - val_accuracy: 0.9721 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0289 - accuracy: 0.9919 - val_loss: 0.1117 - val_accuracy: 0.9779 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.1121 - val_accuracy: 0.9766 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.1256 - val_accuracy: 0.9729 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.1350 - val_accuracy: 0.9750 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.1277 - val_accuracy: 0.9737 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.1231 - val_accuracy: 0.9754 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.1287 - val_accuracy: 0.9754 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 0.1284 - val_accuracy: 0.9754 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 3,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}\n",
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values\n",
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    print(f\"Subset: {idx}, train records: {train_subsets[idx].shape[0]}, validation: {val_subsets[idx].shape[0]}\")\n",
    "    print(f\"Liczba wspólnych dla train i val: {len(set(train_subsets[idx]['doc']).intersection(set(val_subsets[idx]['doc'])))}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=MovingWindowSentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n",
    "\n",
    "master_results={3:results}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0, train records: 10966, validation: 2784\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 6s 12ms/step - loss: 0.2074 - accuracy: 0.9246 - val_loss: 0.3848 - val_accuracy: 0.8646 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0777 - val_accuracy: 0.9835 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.0426 - val_accuracy: 0.9896 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.0558 - val_accuracy: 0.9846 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.1003 - val_accuracy: 0.9713 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0287 - val_accuracy: 0.9917 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0418 - val_accuracy: 0.9892 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0289 - val_accuracy: 0.9914 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0441 - val_accuracy: 0.9907 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0528 - val_accuracy: 0.9892 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0488 - val_accuracy: 0.9899 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0474 - val_accuracy: 0.9907 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0480 - val_accuracy: 0.9899 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0524 - val_accuracy: 0.9878 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0504 - val_accuracy: 0.9899 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0517 - val_accuracy: 0.9885 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9917\n",
      "Subset: 1, train records: 11074, validation: 2676\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 6s 12ms/step - loss: 0.2115 - accuracy: 0.9226 - val_loss: 0.3828 - val_accuracy: 0.8475 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0358 - accuracy: 0.9889 - val_loss: 0.0877 - val_accuracy: 0.9746 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0522 - val_accuracy: 0.9828 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0582 - val_accuracy: 0.9794 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0619 - val_accuracy: 0.9839 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1047 - val_accuracy: 0.9821 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0775 - val_accuracy: 0.9880 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0777 - val_accuracy: 0.9880 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0825 - val_accuracy: 0.9880 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0773 - val_accuracy: 0.9873 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0723 - val_accuracy: 0.9873 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0831 - val_accuracy: 0.9880 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0793 - val_accuracy: 0.9873 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9828\n",
      "Subset: 2, train records: 10888, validation: 2862\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 5s 12ms/step - loss: 0.2184 - accuracy: 0.9199 - val_loss: 0.3910 - val_accuracy: 0.8742 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.1253 - val_accuracy: 0.9605 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.1105 - val_accuracy: 0.9644 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.1537 - val_accuracy: 0.9710 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.1793 - val_accuracy: 0.9595 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.4282 - val_accuracy: 0.9050 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.2080 - val_accuracy: 0.9542 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.2125 - val_accuracy: 0.9549 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.2457 - val_accuracy: 0.9535 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.2688 - val_accuracy: 0.9507 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.2524 - val_accuracy: 0.9507 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.2779 - val_accuracy: 0.9500 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.2586 - val_accuracy: 0.9535 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9644\n",
      "Subset: 3, train records: 10760, validation: 2990\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 6s 12ms/step - loss: 0.2255 - accuracy: 0.9164 - val_loss: 0.5565 - val_accuracy: 0.7602 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0439 - accuracy: 0.9839 - val_loss: 0.1589 - val_accuracy: 0.9468 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0926 - val_accuracy: 0.9672 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.1003 - val_accuracy: 0.9722 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0477 - val_accuracy: 0.9816 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0571 - val_accuracy: 0.9786 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0331 - val_accuracy: 0.9856 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0680 - val_accuracy: 0.9783 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9860 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0495 - val_accuracy: 0.9860 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0453 - val_accuracy: 0.9866 - lr: 2.8946e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0440 - val_accuracy: 0.9880 - lr: 2.8946e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0581 - val_accuracy: 0.9819 - lr: 2.8946e-04\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0571 - val_accuracy: 0.9819 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0575 - val_accuracy: 0.9826 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0642 - val_accuracy: 0.9819 - lr: 1.2890e-04\n",
      "Epoch 17/100\n",
      "193/193 [==============================] - 2s 8ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0620 - val_accuracy: 0.9819 - lr: 5.7401e-05\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9856\n",
      "Subset: 4, train records: 11312, validation: 2438\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 11ms/step - loss: 0.2090 - accuracy: 0.9217 - val_loss: 0.3561 - val_accuracy: 0.9114 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.1135 - val_accuracy: 0.9692 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0913 - val_accuracy: 0.9651 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1450 - val_accuracy: 0.9660 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.1968 - val_accuracy: 0.9643 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.2068 - val_accuracy: 0.9610 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1604 - val_accuracy: 0.9692 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.1981 - val_accuracy: 0.9643 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1940 - val_accuracy: 0.9651 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1847 - val_accuracy: 0.9676 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1896 - val_accuracy: 0.9676 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1903 - val_accuracy: 0.9676 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1887 - val_accuracy: 0.9676 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9651\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 5,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}\n",
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values\n",
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    print(f\"Subset: {idx}, train records: {train_subsets[idx].shape[0]}, validation: {val_subsets[idx].shape[0]}\")\n",
    "    print(f\"Liczba wspólnych dla train i val: {len(set(train_subsets[idx]['doc']).intersection(set(val_subsets[idx]['doc'])))}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=MovingWindowSentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n",
    "\n",
    "master_results[5]=results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Window size = 7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 0, train records: 10966, validation: 2784\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 6s 13ms/step - loss: 0.2084 - accuracy: 0.9218 - val_loss: 0.5070 - val_accuracy: 0.8948 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0390 - accuracy: 0.9863 - val_loss: 0.0698 - val_accuracy: 0.9864 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.0372 - val_accuracy: 0.9896 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0332 - val_accuracy: 0.9917 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0550 - val_accuracy: 0.9853 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0803 - val_accuracy: 0.9781 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0276 - val_accuracy: 0.9903 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.2573 - val_accuracy: 0.9415 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0194 - val_accuracy: 0.9921 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0303 - val_accuracy: 0.9914 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0687 - val_accuracy: 0.9838 - lr: 6.5000e-04\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0338 - val_accuracy: 0.9921 - lr: 6.5000e-04\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0462 - val_accuracy: 0.9917 - lr: 2.8946e-04\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0478 - val_accuracy: 0.9917 - lr: 2.8946e-04\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0483 - val_accuracy: 0.9910 - lr: 2.8946e-04\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0484 - val_accuracy: 0.9910 - lr: 1.2890e-04\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0472 - val_accuracy: 0.9910 - lr: 1.2890e-04\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0480 - val_accuracy: 0.9910 - lr: 1.2890e-04\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0475 - val_accuracy: 0.9910 - lr: 5.7401e-05\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9921\n",
      "Subset: 1, train records: 11074, validation: 2676\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "198/198 [==============================] - 6s 13ms/step - loss: 0.2072 - accuracy: 0.9210 - val_loss: 0.4321 - val_accuracy: 0.8468 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0429 - accuracy: 0.9845 - val_loss: 0.0838 - val_accuracy: 0.9798 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0343 - val_accuracy: 0.9933 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0392 - val_accuracy: 0.9851 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0384 - val_accuracy: 0.9892 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0312 - val_accuracy: 0.9910 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0391 - val_accuracy: 0.9892 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0215 - val_accuracy: 0.9959 - lr: 6.5000e-04\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0413 - val_accuracy: 0.9880 - lr: 6.5000e-04\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0179 - val_accuracy: 0.9974 - lr: 6.5000e-04\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0849 - val_accuracy: 0.9809 - lr: 6.5000e-04\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0317 - val_accuracy: 0.9948 - lr: 6.5000e-04\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0279 - val_accuracy: 0.9933 - lr: 6.5000e-04\n",
      "Epoch 14/100\n",
      "198/198 [==============================] - 2s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0213 - val_accuracy: 0.9970 - lr: 2.8946e-04\n",
      "Epoch 15/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0302 - val_accuracy: 0.9936 - lr: 2.8946e-04\n",
      "Epoch 16/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0295 - val_accuracy: 0.9944 - lr: 2.8946e-04\n",
      "Epoch 17/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0247 - val_accuracy: 0.9959 - lr: 1.2890e-04\n",
      "Epoch 18/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0245 - val_accuracy: 0.9966 - lr: 1.2890e-04\n",
      "Epoch 19/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0233 - val_accuracy: 0.9974 - lr: 1.2890e-04\n",
      "Epoch 20/100\n",
      "198/198 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0235 - val_accuracy: 0.9974 - lr: 5.7401e-05\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0179 - accuracy: 0.9974\n",
      "Subset: 2, train records: 10888, validation: 2862\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "195/195 [==============================] - 6s 13ms/step - loss: 0.2193 - accuracy: 0.9182 - val_loss: 0.2994 - val_accuracy: 0.8588 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.1379 - val_accuracy: 0.9584 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.2273 - val_accuracy: 0.9399 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.2812 - val_accuracy: 0.9392 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.2773 - val_accuracy: 0.9483 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.4073 - val_accuracy: 0.9340 - lr: 2.8946e-04\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4351 - val_accuracy: 0.9354 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4501 - val_accuracy: 0.9357 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4628 - val_accuracy: 0.9340 - lr: 1.2890e-04\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.4595 - val_accuracy: 0.9371 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4652 - val_accuracy: 0.9371 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.4779 - val_accuracy: 0.9357 - lr: 5.7401e-05\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9584\n",
      "Subset: 3, train records: 10760, validation: 2990\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "193/193 [==============================] - 6s 15ms/step - loss: 0.2176 - accuracy: 0.9160 - val_loss: 0.4821 - val_accuracy: 0.8478 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.1236 - val_accuracy: 0.9635 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0233 - accuracy: 0.9932 - val_loss: 0.0875 - val_accuracy: 0.9666 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9880 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0528 - val_accuracy: 0.9860 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0651 - val_accuracy: 0.9863 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1255 - val_accuracy: 0.9696 - lr: 6.5000e-04\n",
      "Epoch 8/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0361 - val_accuracy: 0.9896 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0393 - val_accuracy: 0.9896 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0399 - val_accuracy: 0.9903 - lr: 2.8946e-04\n",
      "Epoch 11/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0369 - val_accuracy: 0.9903 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0324 - val_accuracy: 0.9910 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0426 - val_accuracy: 0.9896 - lr: 1.2890e-04\n",
      "Epoch 14/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0405 - val_accuracy: 0.9903 - lr: 1.2890e-04\n",
      "Epoch 15/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0335 - val_accuracy: 0.9903 - lr: 1.2890e-04\n",
      "Epoch 16/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0397 - val_accuracy: 0.9903 - lr: 5.7401e-05\n",
      "Epoch 17/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0403 - val_accuracy: 0.9903 - lr: 5.7401e-05\n",
      "Epoch 18/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0391 - val_accuracy: 0.9903 - lr: 5.7401e-05\n",
      "Epoch 19/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0404 - val_accuracy: 0.9903 - lr: 2.5561e-05\n",
      "Epoch 20/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0404 - val_accuracy: 0.9903 - lr: 2.5561e-05\n",
      "Epoch 21/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0384 - val_accuracy: 0.9903 - lr: 2.5561e-05\n",
      "Epoch 22/100\n",
      "193/193 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0389 - val_accuracy: 0.9903 - lr: 1.1383e-05\n",
      "94/94 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 0.9910\n",
      "Subset: 4, train records: 11312, validation: 2438\n",
      "Liczba wspólnych dla train i val: 0\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 5s 12ms/step - loss: 0.2180 - accuracy: 0.9174 - val_loss: 0.3679 - val_accuracy: 0.8191 - lr: 6.5000e-04\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0360 - accuracy: 0.9868 - val_loss: 0.1114 - val_accuracy: 0.9639 - lr: 6.5000e-04\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0876 - val_accuracy: 0.9787 - lr: 6.5000e-04\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.2138 - val_accuracy: 0.9623 - lr: 6.5000e-04\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1253 - val_accuracy: 0.9672 - lr: 6.5000e-04\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1646 - val_accuracy: 0.9639 - lr: 6.5000e-04\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1867 - val_accuracy: 0.9643 - lr: 2.8946e-04\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1555 - val_accuracy: 0.9668 - lr: 2.8946e-04\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1377 - val_accuracy: 0.9701 - lr: 2.8946e-04\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.1590 - val_accuracy: 0.9676 - lr: 1.2890e-04\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1324 - val_accuracy: 0.9733 - lr: 1.2890e-04\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1383 - val_accuracy: 0.9733 - lr: 1.2890e-04\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.1481 - val_accuracy: 0.9701 - lr: 5.7401e-05\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"output_class_count\": 3,\n",
    "    \"vocab_size\": 8000,\n",
    "    \"output_sequence_length\": 45,\n",
    "    \"embedding_dimension\": 150,\n",
    "    \"window_size\": 7,\n",
    "    \"conv1d_0_units\": 80,\n",
    "    \"conv1d_0_kernelsize\": 3,\n",
    "    \"conv1d_0_padding\": \"valid\",\n",
    "    \"conv1d_0_activation\": \"relu\",\n",
    "    \"conv1d_1_units\": 80,\n",
    "    \"conv1d_1_kernelsize\": 3,\n",
    "    \"conv1d_1_padding\": \"valid\",\n",
    "    \"conv1d_1_activation\": \"relu\",\n",
    "    \"gru_0_units\": 128,\n",
    "    \"gru_1_units\": 64,\n",
    "    \"drop_0_rate\": 0.3448836829019953,\n",
    "    \"initial_lr\": 0.0006500000000000001,\n",
    "    \"lr_reduction_factor\": 0.44531593652922397,\n",
    "    \"lr_reduction_patience\": 3,\n",
    "    \"batch_size\": 56,\n",
    "    \"max_epochs\": 100,\n",
    "    \"early_stop_patience\": 10\n",
    "}\n",
    "RANDOM_STATE=123\n",
    "df = prepare_dataset(DATAPATH)\n",
    "train_subsets, val_subsets = split_dataset(df, RANDOM_STATE)\n",
    "\n",
    "texts = df['sentence'].values\n",
    "results={}\n",
    "for idx in range(len(train_subsets)):\n",
    "    print(f\"Subset: {idx}, train records: {train_subsets[idx].shape[0]}, validation: {val_subsets[idx].shape[0]}\")\n",
    "    print(f\"Liczba wspólnych dla train i val: {len(set(train_subsets[idx]['doc']).intersection(set(val_subsets[idx]['doc'])))}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    clf=MovingWindowSentenceClassifier(\n",
    "        model_params=model_params,\n",
    "        bod_line = 'This is the first line of document. No lines come before.',\n",
    "        eod_line='This is the last line of document. No lines come after.',\n",
    "        corpus=texts)\n",
    "    clf.prepare_train_records(data=train_subsets[idx])\n",
    "    clf.prepare_validation_records(data=val_subsets[idx])\n",
    "    clf.compile(optimizer=tf.keras.optimizers.Adam(model_params['initial_lr']),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    clf.fit(\n",
    "            x=clf.train_texts, y=clf.train_labels,\n",
    "            batch_size=model_params['batch_size'],\n",
    "            epochs=model_params['max_epochs'],\n",
    "            validation_data=(clf.validation_texts, clf.validation_labels),\n",
    "            use_multiprocessing=True,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                    factor=model_params['lr_reduction_factor'], patience=model_params['lr_reduction_patience'], verbose=0),\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    min_delta=1e-4, patience=model_params['early_stop_patience'], restore_best_weights=True)\n",
    "            ],verbose=1)\n",
    "    results[idx]=clf.evaluate(clf.validation_texts, clf.validation_labels)\n",
    "\n",
    "master_results[7]=results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1400x600 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_={(k,s): {'val_loss':master_results[k][s][0], 'val_accuracy': master_results[k][s][1]}\n",
    " for k in master_results.keys() for s in master_results[k].keys()}\n",
    "_ = pd.DataFrame.from_dict(_).T.reset_index()\n",
    "_.columns=['window size','split num', 'val loss', 'val accuracy']\n",
    "\n",
    "fig, ax=plt.subplots(1,2,figsize=(14,6))\n",
    "sns.barplot(data=_, x= 'split num', y='val loss', hue='window size',palette='rainbow', ax=ax[0])\n",
    "ax[0].set_title(\"Validation loss values for window sizes\")\n",
    "ax[0].set_ylim(_['val loss'].min()-0.01, _['val loss'].max()+0.01)\n",
    "sns.barplot(data=_, x= 'split num', y='val accuracy', hue='window size',palette='rainbow', ax=ax[1])\n",
    "ax[1].set_title(\"Validation accuracy values for window sizes\")\n",
    "ax[1].set_ylim(_['val accuracy'].min()-0.01, 1.0);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 0:07:22.500871\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total execution time: {dt.datetime.now()-start}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py38_tf29",
   "language": "python",
   "display_name": "py38_tf29"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
